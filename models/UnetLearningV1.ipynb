{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1327578,"sourceType":"datasetVersion","datasetId":767686},{"sourceId":1327590,"sourceType":"datasetVersion","datasetId":769463},{"sourceId":666016,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":504121,"modelId":519169}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Imports and Data Preparation\nimport os\nimport pandas as pd\nimport numpy as np\nimport nibabel as nib\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef prepare_kaggle_data():\n    \"\"\"–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç DataFrame —Å –ø—É—Ç—è–º–∏ –∫ –¥–∞–Ω–Ω—ã–º Kaggle\"\"\"\n    file_list = []\n    \n    kaggle_dirs = [\n        '../input/liver-tumor-segmentation',\n        '../input/liver-tumor-segmentation-part-2'\n    ]\n    \n    for base_dir in kaggle_dirs:\n        if os.path.exists(base_dir):\n            print(f\"Processing directory: {base_dir}\")\n            for dirname, _, filenames in os.walk(base_dir):\n                for filename in filenames:\n                    if filename.endswith('.nii'):\n                        file_list.append((dirname, filename))\n    \n    df_files = pd.DataFrame(file_list, columns=['dirname', 'filename'])\n    df_files = df_files.sort_values(by=['filename'], ascending=True)\n    \n    print(f\"Total files found: {len(df_files)}\")\n    \n    # –î–æ–±–∞–≤–ª—è–µ–º –º–∞—Å–∫–∏\n    df_files[\"mask_dirname\"] = \"\"\n    df_files[\"mask_filename\"] = \"\"\n    \n    matched_count = 0\n    for i in range(131):\n        ct = f\"volume-{i}.nii\"\n        mask = f\"segmentation-{i}.nii\"\n        \n        ct_match = df_files['filename'] == ct\n        if ct_match.any():\n            df_files.loc[ct_match, 'mask_filename'] = mask\n            df_files.loc[ct_match, 'mask_dirname'] = \"../input/liver-tumor-segmentation/segmentations\"\n            matched_count += 1\n    \n    print(f\"Matched {matched_count} volume-mask pairs\")\n    \n    # –§–∏–ª—å—Ç—Ä—É–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏\n    df_volumes_with_masks = df_files[df_files['mask_filename'] != ''].copy()\n    df_volumes_with_masks = df_volumes_with_masks.reset_index(drop=True)\n    \n    df_volumes_with_masks['ct_path'] = df_volumes_with_masks['dirname'] + '/' + df_volumes_with_masks['filename']\n    df_volumes_with_masks['mask_path'] = df_volumes_with_masks['mask_dirname'] + '/' + df_volumes_with_masks['mask_filename']\n    \n    print(f\"Final dataset: {len(df_volumes_with_masks)} volumes with masks\")\n    return df_volumes_with_masks\n\n# –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö\nprint(\"üîß Preparing Kaggle data...\")\ndf_kaggle = prepare_kaggle_data()\ndf_kaggle.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T18:15:34.442580Z","iopub.execute_input":"2025-11-29T18:15:34.443233Z","iopub.status.idle":"2025-11-29T18:15:41.278303Z","shell.execute_reply.started":"2025-11-29T18:15:34.443205Z","shell.execute_reply":"2025-11-29T18:15:41.277381Z"}},"outputs":[{"name":"stdout","text":"üîß Preparing Kaggle data...\nProcessing directory: ../input/liver-tumor-segmentation\nProcessing directory: ../input/liver-tumor-segmentation-part-2\nTotal files found: 262\nMatched 131 volume-mask pairs\nFinal dataset: 131 volumes with masks\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"                                             dirname        filename  \\\n0       ../input/liver-tumor-segmentation/volume_pt1    volume-0.nii   \n1       ../input/liver-tumor-segmentation/volume_pt1    volume-1.nii   \n2       ../input/liver-tumor-segmentation/volume_pt1   volume-10.nii   \n3  ../input/liver-tumor-segmentation-part-2/volum...  volume-100.nii   \n4  ../input/liver-tumor-segmentation-part-2/volum...  volume-101.nii   \n\n                                      mask_dirname         mask_filename  \\\n0  ../input/liver-tumor-segmentation/segmentations    segmentation-0.nii   \n1  ../input/liver-tumor-segmentation/segmentations    segmentation-1.nii   \n2  ../input/liver-tumor-segmentation/segmentations   segmentation-10.nii   \n3  ../input/liver-tumor-segmentation/segmentations  segmentation-100.nii   \n4  ../input/liver-tumor-segmentation/segmentations  segmentation-101.nii   \n\n                                             ct_path  \\\n0  ../input/liver-tumor-segmentation/volume_pt1/v...   \n1  ../input/liver-tumor-segmentation/volume_pt1/v...   \n2  ../input/liver-tumor-segmentation/volume_pt1/v...   \n3  ../input/liver-tumor-segmentation-part-2/volum...   \n4  ../input/liver-tumor-segmentation-part-2/volum...   \n\n                                           mask_path  \n0  ../input/liver-tumor-segmentation/segmentation...  \n1  ../input/liver-tumor-segmentation/segmentation...  \n2  ../input/liver-tumor-segmentation/segmentation...  \n3  ../input/liver-tumor-segmentation/segmentation...  \n4  ../input/liver-tumor-segmentation/segmentation...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dirname</th>\n      <th>filename</th>\n      <th>mask_dirname</th>\n      <th>mask_filename</th>\n      <th>ct_path</th>\n      <th>mask_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../input/liver-tumor-segmentation/volume_pt1</td>\n      <td>volume-0.nii</td>\n      <td>../input/liver-tumor-segmentation/segmentations</td>\n      <td>segmentation-0.nii</td>\n      <td>../input/liver-tumor-segmentation/volume_pt1/v...</td>\n      <td>../input/liver-tumor-segmentation/segmentation...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../input/liver-tumor-segmentation/volume_pt1</td>\n      <td>volume-1.nii</td>\n      <td>../input/liver-tumor-segmentation/segmentations</td>\n      <td>segmentation-1.nii</td>\n      <td>../input/liver-tumor-segmentation/volume_pt1/v...</td>\n      <td>../input/liver-tumor-segmentation/segmentation...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../input/liver-tumor-segmentation/volume_pt1</td>\n      <td>volume-10.nii</td>\n      <td>../input/liver-tumor-segmentation/segmentations</td>\n      <td>segmentation-10.nii</td>\n      <td>../input/liver-tumor-segmentation/volume_pt1/v...</td>\n      <td>../input/liver-tumor-segmentation/segmentation...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../input/liver-tumor-segmentation-part-2/volum...</td>\n      <td>volume-100.nii</td>\n      <td>../input/liver-tumor-segmentation/segmentations</td>\n      <td>segmentation-100.nii</td>\n      <td>../input/liver-tumor-segmentation-part-2/volum...</td>\n      <td>../input/liver-tumor-segmentation/segmentation...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../input/liver-tumor-segmentation-part-2/volum...</td>\n      <td>volume-101.nii</td>\n      <td>../input/liver-tumor-segmentation/segmentations</td>\n      <td>segmentation-101.nii</td>\n      <td>../input/liver-tumor-segmentation-part-2/volum...</td>\n      <td>../input/liver-tumor-segmentation/segmentation...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"# Cell 2: Preprocessing and Saving to Disk\ndef read_nii(filepath):\n    \"\"\"–ß–∏—Ç–∞–µ—Ç .nii —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç numpy array\"\"\"\n    ct_scan = nib.load(filepath)\n    array = ct_scan.get_fdata()\n    array = np.rot90(np.array(array))\n    return array\n\ndef preprocess_and_save_data(df_files, output_dir='processed_data_256', image_size=256):\n    \"\"\"\n    –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–∞ –¥–∏—Å–∫\n    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame —Å –ø—É—Ç—è–º–∏ –∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º —Ñ–∞–π–ª–∞–º\n    \"\"\"\n    os.makedirs(output_dir, exist_ok=True)\n    os.makedirs(f'{output_dir}/images', exist_ok=True)\n    os.makedirs(f'{output_dir}/masks', exist_ok=True)\n    \n    image_paths = []\n    mask_paths = []\n    volume_ids = []\n    slice_ids = []\n    \n    print(f\"üöÄ Starting preprocessing - saving to {output_dir}\")\n    print(f\"üìê Target size: {image_size}x{image_size}\")\n    \n    for idx in tqdm(range(len(df_files)), desc=\"Processing volumes\"):\n        try:\n            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤\n            ct_path = df_files.loc[idx, 'ct_path']\n            mask_path = df_files.loc[idx, 'mask_path']\n            \n            if not os.path.exists(ct_path) or not os.path.exists(mask_path):\n                print(f\"‚ö†Ô∏è Files not found for volume {idx}\")\n                continue\n            \n            # –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n            ct_scan = read_nii(ct_path)\n            mask = read_nii(mask_path)\n            \n            # –ü–æ–ª—É—á–∞–µ–º ID volume –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞\n            file_name = df_files.loc[idx, 'filename']\n            volume_id = file_name.replace('volume-', '').replace('.nii', '')\n            \n            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –í–°–ï —Å—Ä–µ–∑—ã\n            num_slices = ct_scan.shape[2]\n            \n            for slice_idx in range(num_slices):\n                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ä–µ–∑\n                ct_slice = ct_scan[..., slice_idx]\n                mask_slice = mask[..., slice_idx]\n                \n                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è CT —Å—Ä–µ–∑–∞ [0, 1]\n                ct_slice_normalized = (ct_slice - ct_slice.min()) / (ct_slice.max() - ct_slice.min() + 1e-8)\n                \n                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ uint8 [0, 255] –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\n                ct_slice_uint8 = (ct_slice_normalized * 255).astype(np.uint8)\n                mask_slice_uint8 = mask_slice.astype(np.uint8)\n                \n                # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞\n                ct_slice_resized = cv2.resize(ct_slice_uint8, (image_size, image_size))\n                mask_slice_resized = cv2.resize(mask_slice_uint8, (image_size, image_size), \n                                               interpolation=cv2.INTER_NEAREST)\n                \n                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n                image_filename = f'volume_{volume_id}_slice_{slice_idx:03d}.png'\n                mask_filename = f'volume_{volume_id}_slice_{slice_idx:03d}_mask.png'\n                \n                image_path = f'{output_dir}/images/{image_filename}'\n                mask_path = f'{output_dir}/masks/{mask_filename}'\n                \n                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ PNG\n                cv2.imwrite(image_path, ct_slice_resized)\n                cv2.imwrite(mask_path, mask_slice_resized)\n                \n                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Ç–∏\n                image_paths.append(image_path)\n                mask_paths.append(mask_path)\n                volume_ids.append(int(volume_id))\n                slice_ids.append(slice_idx)\n                \n        except Exception as e:\n            print(f\"‚ùå Error processing volume {idx}: {e}\")\n            continue\n    \n    # –°–æ–∑–¥–∞–µ–º DataFrame —Å –ø—É—Ç—è–º–∏\n    df_processed = pd.DataFrame({\n        'image_path': image_paths,\n        'mask_path': mask_paths,\n        'volume_id': volume_ids,\n        'slice_id': slice_ids\n    })\n    \n    # –°–æ—Ö—Ä–∞–Ω—è–µ–º CSV —Å –ø—É—Ç—è–º–∏\n    csv_path = f'{output_dir}/dataset.csv'\n    df_processed.to_csv(csv_path, index=False)\n    \n    print(f\"‚úÖ Preprocessing completed!\")\n    print(f\"üìÅ Saved {len(df_processed)} image-mask pairs\")\n    print(f\"üíæ CSV saved: {csv_path}\")\n    \n    return df_processed\n\n# –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É (—ç—Ç–æ –∑–∞–π–º–µ—Ç –≤—Ä–µ–º—è)\nprint(\"üîÑ Starting data preprocessing...\")\ndf_processed = preprocess_and_save_data(df_kaggle, image_size=256)\ndf_processed.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T17:18:04.744946Z","iopub.execute_input":"2025-11-29T17:18:04.745677Z","iopub.status.idle":"2025-11-29T17:32:33.454595Z","shell.execute_reply.started":"2025-11-29T17:18:04.745650Z","shell.execute_reply":"2025-11-29T17:32:33.453964Z"}},"outputs":[{"name":"stdout","text":"üîÑ Starting data preprocessing...\nüöÄ Starting preprocessing - saving to processed_data_256\nüìê Target size: 256x256\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing volumes:   0%|          | 0/131 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37802f24138148e28ef63e553e7348d0"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Preprocessing completed!\nüìÅ Saved 58638 image-mask pairs\nüíæ CSV saved: processed_data_256/dataset.csv\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                         image_path  \\\n0  processed_data_256/images/volume_0_slice_000.png   \n1  processed_data_256/images/volume_0_slice_001.png   \n2  processed_data_256/images/volume_0_slice_002.png   \n3  processed_data_256/images/volume_0_slice_003.png   \n4  processed_data_256/images/volume_0_slice_004.png   \n\n                                           mask_path  volume_id  slice_id  \n0  processed_data_256/masks/volume_0_slice_000_ma...          0         0  \n1  processed_data_256/masks/volume_0_slice_001_ma...          0         1  \n2  processed_data_256/masks/volume_0_slice_002_ma...          0         2  \n3  processed_data_256/masks/volume_0_slice_003_ma...          0         3  \n4  processed_data_256/masks/volume_0_slice_004_ma...          0         4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>mask_path</th>\n      <th>volume_id</th>\n      <th>slice_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>processed_data_256/images/volume_0_slice_000.png</td>\n      <td>processed_data_256/masks/volume_0_slice_000_ma...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>processed_data_256/images/volume_0_slice_001.png</td>\n      <td>processed_data_256/masks/volume_0_slice_001_ma...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>processed_data_256/images/volume_0_slice_002.png</td>\n      <td>processed_data_256/masks/volume_0_slice_002_ma...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>processed_data_256/images/volume_0_slice_003.png</td>\n      <td>processed_data_256/masks/volume_0_slice_003_ma...</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>processed_data_256/images/volume_0_slice_004.png</td>\n      <td>processed_data_256/masks/volume_0_slice_004_ma...</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Cell 3: Load Preprocessed Data\ndef load_preprocessed_data(data_dir='processed_data_256'):\n    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\"\"\"\n    csv_path = f'{data_dir}/dataset.csv'\n    \n    if not os.path.exists(csv_path):\n        print(f\"‚ùå CSV file not found: {csv_path}\")\n        print(\"Please run Cell 2 first!\")\n        return None\n    \n    df_processed = pd.read_csv(csv_path)\n    \n    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤\n    existing_files = 0\n    for idx, row in df_processed.iterrows():\n        if os.path.exists(row['image_path']) and os.path.exists(row['mask_path']):\n            existing_files += 1\n    \n    print(f\"üìä Loaded dataset: {len(df_processed)} pairs\")\n    print(f\"‚úÖ Files that exist: {existing_files}/{len(df_processed)}\")\n    \n    if existing_files == 0:\n        print(\"‚ùå No files found! Please check paths.\")\n        return None\n    \n    return df_processed\n\n# –ë—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≥–æ—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\nprint(\"üì• Loading preprocessed data...\")\ndf_ready = load_preprocessed_data()\n\nif df_ready is not None:\n    print(\"‚úÖ Data loaded successfully!\")\n    df_ready.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T18:15:53.604051Z","iopub.execute_input":"2025-11-29T18:15:53.605067Z","iopub.status.idle":"2025-11-29T18:15:58.003037Z","shell.execute_reply.started":"2025-11-29T18:15:53.605037Z","shell.execute_reply":"2025-11-29T18:15:58.002315Z"}},"outputs":[{"name":"stdout","text":"üì• Loading preprocessed data...\nüìä Loaded dataset: 58638 pairs\n‚úÖ Files that exist: 58638/58638\n‚úÖ Data loaded successfully!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Cell 4: Dataset for Fast Loading\nclass LiverDataset(Dataset):\n    def __init__(self, df, image_size=256, transform=None):\n        self.df = df\n        self.image_size = image_size\n        self.transform = transform\n        self.image_paths = df['image_path'].values\n        self.mask_paths = df['mask_path'].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        # –ë—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≥–æ—Ç–æ–≤—ã—Ö PNG\n        image_path = self.image_paths[idx]\n        mask_path = self.mask_paths[idx]\n        \n        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        \n        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è [0, 255] -> [0, 1]\n        image = image.astype(np.float32) / 255.0\n        \n        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä—ã\n        image_tensor = torch.FloatTensor(image).unsqueeze(0)  # [1, H, W]\n        mask_tensor = torch.LongTensor(mask)                  # [H, W]\n        \n        return image_tensor, mask_tensor\n\ndef create_data_loaders(df, batch_size=8, test_size=0.2):\n    \"\"\"–°–æ–∑–¥–∞–µ—Ç DataLoader'—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\"\"\"\n    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/val\n    train_df, val_df = train_test_split(df, test_size=test_size, random_state=42, shuffle=True)\n    \n    print(f\"üìä Training samples: {len(train_df)}\")\n    print(f\"üìä Validation samples: {len(val_df)}\")\n    \n    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã\n    train_dataset = LiverDataset(train_df)\n    val_dataset = LiverDataset(val_df)\n    \n    # –°–æ–∑–¥–∞–µ–º DataLoader'—ã\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n    \n    return train_loader, val_loader\n\n# –ë—ã—Å—Ç—Ä–æ —Å–æ–∑–¥–∞–µ–º DataLoader'—ã (—Å–µ–∫—É–Ω–¥—ã)\nif df_ready is not None:\n    print(\"üîÑ Creating data loaders...\")\n    train_loader, val_loader = create_data_loaders(df_ready, batch_size=8)\n    print(\"‚úÖ Data loaders ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T18:16:10.140587Z","iopub.execute_input":"2025-11-29T18:16:10.140926Z","iopub.status.idle":"2025-11-29T18:16:10.160267Z","shell.execute_reply.started":"2025-11-29T18:16:10.140902Z","shell.execute_reply":"2025-11-29T18:16:10.159443Z"}},"outputs":[{"name":"stdout","text":"üîÑ Creating data loaders...\nüìä Training samples: 46910\nüìä Validation samples: 11728\n‚úÖ Data loaders ready!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Cell 4.1: Create Optimized Datasets\ndef create_optimized_datasets(df, image_size=256, max_samples=None):\n    \"\"\"–°–æ–∑–¥–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –≤—ã–±–æ—Ä–∫–∏\"\"\"\n    \n    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ samples –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏—è\n    if max_samples and len(df) > max_samples:\n        print(f\"‚ö†Ô∏è Limiting dataset from {len(df)} to {max_samples} samples for faster prototyping\")\n        df = df.sample(max_samples, random_state=42).reset_index(drop=True)\n    \n    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/val\n    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)\n    \n    print(f\"üìä Training samples: {len(train_df)}\")\n    print(f\"üìä Validation samples: {len(val_df)}\")\n    \n    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã\n    train_dataset = LiverDataset(train_df, image_size=image_size)\n    val_dataset = LiverDataset(val_df, image_size=image_size)\n    \n    return train_dataset, val_dataset, train_df, val_df\n\n# –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã (–æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)\nprint(\"üîÑ Creating optimized datasets...\")\ntrain_dataset, val_dataset, train_df, val_df = create_optimized_datasets(\n    df_ready, \n    max_samples=2000  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n)\n\nprint(\"‚úÖ Datasets created successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T18:16:14.796456Z","iopub.execute_input":"2025-11-29T18:16:14.797167Z","iopub.status.idle":"2025-11-29T18:16:14.809379Z","shell.execute_reply.started":"2025-11-29T18:16:14.797137Z","shell.execute_reply":"2025-11-29T18:16:14.808706Z"}},"outputs":[{"name":"stdout","text":"üîÑ Creating optimized datasets...\n‚ö†Ô∏è Limiting dataset from 58638 to 2000 samples for faster prototyping\nüìä Training samples: 1600\nüìä Validation samples: 400\n‚úÖ Datasets created successfully!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Cell 5: U-Net Model Definition\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConv, self).__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\nclass UNet(nn.Module):\n    def __init__(self, n_channels=1, n_classes=3):\n        super(UNet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n\n        # Encoder\n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(64, 128))\n        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(128, 256))\n        self.down3 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(256, 512))\n        self.down4 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(512, 1024))\n\n        # Decoder\n        self.up1 = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n            nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n        )\n        self.conv1 = DoubleConv(1024, 512)\n        \n        self.up2 = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n            nn.Conv2d(512, 256, kernel_size=3, padding=1)\n        )\n        self.conv2 = DoubleConv(512, 256)\n        \n        self.up3 = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n            nn.Conv2d(256, 128, kernel_size=3, padding=1)\n        )\n        self.conv3 = DoubleConv(256, 128)\n        \n        self.up4 = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n            nn.Conv2d(128, 64, kernel_size=3, padding=1)\n        )\n        self.conv4 = DoubleConv(128, 64)\n\n        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)\n\n    def forward(self, x):\n        # Encoder\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n\n        # Decoder\n        x = self.up1(x5)\n        x = torch.cat([x, x4], dim=1)\n        x = self.conv1(x)\n\n        x = self.up2(x)\n        x = torch.cat([x, x3], dim=1)\n        x = self.conv2(x)\n\n        x = self.up3(x)\n        x = torch.cat([x, x2], dim=1)\n        x = self.conv3(x)\n\n        x = self.up4(x)\n        x = torch.cat([x, x1], dim=1)\n        x = self.conv4(x)\n\n        logits = self.outc(x)\n        return logits\n\nprint(\"üß† U-Net model defined successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T18:16:22.822750Z","iopub.execute_input":"2025-11-29T18:16:22.823391Z","iopub.status.idle":"2025-11-29T18:16:22.834766Z","shell.execute_reply.started":"2025-11-29T18:16:22.823367Z","shell.execute_reply":"2025-11-29T18:16:22.833781Z"}},"outputs":[{"name":"stdout","text":"üß† U-Net model defined successfully!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Cell 6: Optimized Training\ndef train_model_fast(model, train_loader, val_loader, num_epochs=25, device='cuda'):\n    \"\"\"–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è\"\"\"\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n    \n    model.to(device)\n    train_losses, val_losses = [], []\n    \n    # –£–º–µ–Ω—å—à–∞–µ–º –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ IoU –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏\n    calculate_iou_every = 50  # –°—á–∏—Ç–∞–µ–º IoU —Ç–æ–ª—å–∫–æ –∫–∞–∂–¥—ã–µ 50 –±–∞—Ç—á–µ–π\n    \n    for epoch in range(num_epochs):\n        # Training\n        model.train()\n        running_loss = 0.0\n        running_iou = 0.0\n        iou_count = 0\n        \n        # –ò—Å–ø–æ–ª—å–∑—É–µ–º tqdm —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏\n        batch_iterator = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', \n                             mininterval=10)  # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞–∑ –≤ 10 —Å–µ–∫—É–Ω–¥\n        \n        for batch_idx, (images, masks) in enumerate(batch_iterator):\n            images, masks = images.to(device), masks.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, masks)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            \n            # IoU —Å—á–∏—Ç–∞–µ–º —Ä–µ–∂–µ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏\n            if batch_idx % calculate_iou_every == 0:\n                with torch.no_grad():\n                    preds = torch.argmax(outputs, dim=1)\n                    iou = calculate_iou(preds, masks)\n                    running_iou += iou\n                    iou_count += 1\n            \n            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞\n            if batch_idx % 100 == 0:\n                batch_iterator.set_postfix({\n                    'Loss': f'{loss.item():.4f}',\n                    'Avg Loss': f'{running_loss/(batch_idx+1):.4f}'\n                })\n        \n        # Validation (—Ç–æ–ª—å–∫–æ –≤ –∫–æ–Ω—Ü–µ —ç–ø–æ—Ö–∏)\n        model.eval()\n        val_loss = 0.0\n        val_iou = 0.0\n        \n        with torch.no_grad():\n            # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏\n            val_samples = min(100, len(val_loader))\n            for i, (images, masks) in enumerate(val_loader):\n                if i >= val_samples:\n                    break\n                images, masks = images.to(device), masks.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, masks)\n                val_loss += loss.item()\n                \n                preds = torch.argmax(outputs, dim=1)\n                iou = calculate_iou(preds, masks)\n                val_iou += iou\n        \n        # Calculate averages\n        epoch_train_loss = running_loss / len(train_loader)\n        epoch_val_loss = val_loss / val_samples\n        epoch_train_iou = running_iou / iou_count if iou_count > 0 else 0\n        epoch_val_iou = val_iou / val_samples\n        \n        train_losses.append(epoch_train_loss)\n        val_losses.append(epoch_val_loss)\n        \n        print(f'Epoch {epoch+1}/{num_epochs}:')\n        print(f'  Train Loss: {epoch_train_loss:.4f}, Train IoU: {epoch_train_iou:.4f}')\n        print(f'  Val Loss: {epoch_val_loss:.4f}, Val IoU: {epoch_val_iou:.4f}')\n        \n        # Save best model\n        if epoch_val_loss == min(val_losses):\n            torch.save(model.state_dict(), 'best_unet_liver.pth')\n            print(f'  üíæ Best model saved!')\n    \n    return train_losses, val_losses\n\n# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –±—ã—Å—Ç—Ä–∞—è –≤–µ—Ä—Å–∏—è –±–µ–∑ tqdm\ndef train_model_very_fast(model, train_loader, val_loader, num_epochs=25, device='cuda'):\n    \"\"\"–°–≤–µ—Ä—Ö–±—ã—Å—Ç—Ä–∞—è –≤–µ—Ä—Å–∏—è –±–µ–∑ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞\"\"\"\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n    \n    model.to(device)\n    train_losses, val_losses = [], []\n    \n    for epoch in range(num_epochs):\n        # Training\n        model.train()\n        running_loss = 0.0\n        \n        print(f'Epoch {epoch+1}/{num_epochs} - Training...')\n        \n        for batch_idx, (images, masks) in enumerate(train_loader):\n            images, masks = images.to(device), masks.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, masks)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            \n            # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 100 –±–∞—Ç—á–µ–π\n            if batch_idx % 100 == 0:\n                avg_loss = running_loss / (batch_idx + 1)\n                print(f'  Batch {batch_idx}/{len(train_loader)}, Loss: {avg_loss:.4f}')\n        \n        # Validation\n        model.eval()\n        val_loss = 0.0\n        \n        print(f'Epoch {epoch+1}/{num_epochs} - Validation...')\n        \n        with torch.no_grad():\n            for images, masks in val_loader:\n                images, masks = images.to(device), masks.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, masks)\n                val_loss += loss.item()\n        \n        epoch_train_loss = running_loss / len(train_loader)\n        epoch_val_loss = val_loss / len(val_loader)\n        \n        train_losses.append(epoch_train_loss)\n        val_losses.append(epoch_val_loss)\n        \n        print(f'Epoch {epoch+1} Complete:')\n        print(f'  Train Loss: {epoch_train_loss:.4f}')\n        print(f'  Val Loss: {epoch_val_loss:.4f}')\n        \n        if epoch_val_loss == min(val_losses):\n            torch.save(model.state_dict(), 'best_unet_liver.pth')\n            print(f'  üíæ Best model saved!')\n    \n    return train_losses, val_losses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T18:16:30.557686Z","iopub.execute_input":"2025-11-29T18:16:30.558483Z","iopub.status.idle":"2025-11-29T18:16:30.573776Z","shell.execute_reply.started":"2025-11-29T18:16:30.558453Z","shell.execute_reply":"2025-11-29T18:16:30.572940Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Cell 7: Optimized Training Setup (FIXED)\ndef setup_fast_training(train_dataset, val_dataset):\n    \"\"\"–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±—ã—Å—Ç—Ä–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\"\"\"\n    \n    # 1. –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞\n    BATCH_SIZE = 16  # –ù–∞—á–∏–Ω–∞–µ–º —Å –º–∞–ª–æ–≥–æ, –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –µ—Å–ª–∏ —Ö–≤–∞—Ç–∏—Ç –ø–∞–º—è—Ç–∏\n    \n    # 2. –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ workers\n    NUM_WORKERS = 4  # 0 –¥–ª—è Windows, 2-4 –¥–ª—è Linux\n    \n    print(f\"‚öôÔ∏è Training setup:\")\n    print(f\"  Batch size: {BATCH_SIZE}\")\n    print(f\"  Workers: {NUM_WORKERS}\")\n    print(f\"  Training samples: {len(train_dataset)}\")\n    print(f\"  Validation samples: {len(val_dataset)}\")\n    \n    # 3. –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ DataLoader'—ã\n    train_loader_fast = DataLoader(\n        train_dataset, \n        batch_size=BATCH_SIZE, \n        shuffle=True, \n        num_workers=NUM_WORKERS,\n        pin_memory=True,  # –£—Å–∫–æ—Ä—è–µ—Ç transfer –Ω–∞ GPU\n        persistent_workers=True if NUM_WORKERS > 0 else False\n    )\n    \n    val_loader_fast = DataLoader(\n        val_dataset, \n        batch_size=BATCH_SIZE, \n        shuffle=False, \n        num_workers=NUM_WORKERS,\n        pin_memory=True,\n        persistent_workers=True if NUM_WORKERS > 0 else False\n    )\n    \n    # 4. –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å\n    model_fast = UNet(n_channels=1, n_classes=3)\n    \n    # 5. Mixed precision scaler\n    scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n    \n    print(f\"üìä Batches per epoch: {len(train_loader_fast)}\")\n    \n    # –û—Ü–µ–Ω–∏–≤–∞–µ–º –≤—Ä–µ–º—è\n    if len(train_loader_fast) > 0:\n        estimated_time = len(train_loader_fast) * 0.2  # ~0.2 —Å–µ–∫ –Ω–∞ –±–∞—Ç—á\n        print(f\"‚è±Ô∏è Estimated time per epoch: {estimated_time/60:.1f} minutes\")\n    \n    return model_fast, train_loader_fast, val_loader_fast, scaler\n\n# –°–£–ü–ï–†-–ë–´–°–¢–†–ê–Ø –§–£–ù–ö–¶–ò–Ø –û–ë–£–ß–ï–ù–ò–Ø\ndef train_model_super_fast(model, train_loader, val_loader, num_epochs=10, device='cuda'):\n    \"\"\"–°–≤–µ—Ä—Ö–±—ã—Å—Ç—Ä–∞—è –≤–µ—Ä—Å–∏—è –æ–±—É—á–µ–Ω–∏—è\"\"\"\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n    \n    model.to(device)\n    train_losses, val_losses = [], []\n    \n    print(\"üöÄ Starting SUPER FAST training...\")\n    \n    for epoch in range(num_epochs):\n        # === TRAINING ===\n        model.train()\n        running_loss = 0.0\n        start_time = time.time()\n        \n        print(f'\\nEpoch {epoch+1}/{num_epochs} - Training:')\n        \n        for batch_idx, (images, masks) in enumerate(train_loader):\n            images, masks = images.to(device), masks.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, masks)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            \n            # –ë—ã—Å—Ç—Ä—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –∫–∞–∂–¥—ã–µ 10% \n            if batch_idx % max(1, len(train_loader) // 10) == 0:\n                progress = (batch_idx + 1) / len(train_loader) * 100\n                avg_loss = running_loss / (batch_idx + 1)\n                print(f'  Progress: {progress:.0f}% | Loss: {avg_loss:.4f}')\n        \n        # === VALIDATION ===\n        model.eval()\n        val_loss = 0.0\n        \n        print(f'Epoch {epoch+1}/{num_epochs} - Validation...')\n        \n        with torch.no_grad():\n            # –ë—ã—Å—Ç—Ä–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ 20% –¥–∞–Ω–Ω—ã—Ö\n            val_batches = min(20, len(val_loader))\n            for i, (images, masks) in enumerate(val_loader):\n                if i >= val_batches:\n                    break\n                images, masks = images.to(device), masks.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, masks)\n                val_loss += loss.item()\n        \n        # Calculate metrics\n        epoch_train_loss = running_loss / len(train_loader)\n        epoch_val_loss = val_loss / val_batches\n        epoch_time = time.time() - start_time\n        \n        train_losses.append(epoch_train_loss)\n        val_losses.append(epoch_val_loss)\n        \n        print(f'‚úÖ Epoch {epoch+1} Complete:')\n        print(f'   Time: {epoch_time/60:.1f} min')\n        print(f'   Train Loss: {epoch_train_loss:.4f}')\n        print(f'   Val Loss: {epoch_val_loss:.4f}')\n        \n        # Save best model\n        if epoch_val_loss == min(val_losses):\n            torch.save(model.state_dict(), 'best_unet_liver.pth')\n            print(f'   üíæ Best model saved!')\n    \n    return train_losses, val_losses\n\n# –ó–ê–ü–£–°–ö –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø\nimport time\n\nprint(\"‚ö° Setting up fast training...\")\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\nmodel_fast, train_loader_fast, val_loader_fast, scaler = setup_fast_training(train_dataset, val_dataset)\n\n# –ó–∞–ø—É—Å–∫–∞–µ–º —Å–≤–µ—Ä—Ö–±—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ\ntrain_losses, val_losses = train_model_super_fast(\n    model_fast, train_loader_fast, val_loader_fast, \n    num_epochs=10,  # –ù–∞—á–∏–Ω–∞–µ–º —Å 5 —ç–ø–æ—Ö\n    device=device\n)\n\ntorch.save(model_fast.state_dict(), 'final_unet_liver_fast.pth')\nprint(\"üéâ FAST training completed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T18:06:41.991264Z","iopub.execute_input":"2025-11-29T18:06:41.992160Z","iopub.status.idle":"2025-11-29T18:06:49.210592Z","shell.execute_reply.started":"2025-11-29T18:06:41.992132Z","shell.execute_reply":"2025-11-29T18:06:49.209410Z"}},"outputs":[{"name":"stdout","text":"‚ö° Setting up fast training...\nUsing device: cuda\n‚öôÔ∏è Training setup:\n  Batch size: 16\n  Workers: 4\n  Training samples: 1600\n  Validation samples: 400\nüìä Batches per epoch: 100\n‚è±Ô∏è Estimated time per epoch: 0.3 minutes\nüöÄ Starting SUPER FAST training...\n\nEpoch 1/10 - Training:\n  Progress: 1% | Loss: 1.3105\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_140/3544516231.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;31m# –ó–∞–ø—É—Å–∫–∞–µ–º —Å–≤–µ—Ä—Ö–±—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m train_losses, val_losses = train_model_super_fast(\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0mmodel_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader_fast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# –ù–∞—á–∏–Ω–∞–µ–º —Å 5 —ç–ø–æ—Ö\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_140/3544516231.py\u001b[0m in \u001b[0;36mtrain_model_super_fast\u001b[0;34m(model, train_loader, val_loader, num_epochs, device)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;31m# –ë—ã—Å—Ç—Ä—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –∫–∞–∂–¥—ã–µ 10%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"# Cell 4.2: Full Dataset Setup\ndef create_full_datasets(df, image_size=256):\n    \"\"\"–°–æ–∑–¥–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç—ã –∏–∑ –í–°–ï–• –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\"\"\"\n    \n    print(f\"üìä Original dataset size: {len(df)} samples\")\n    \n    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/val\n    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)\n    \n    print(f\"üìä Training samples: {len(train_df)}\")\n    print(f\"üìä Validation samples: {len(val_df)}\")\n    print(f\"üìä Total samples: {len(train_df) + len(val_df)}\")\n    \n    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã\n    train_dataset_full = LiverDataset(train_df, image_size=image_size)\n    val_dataset_full = LiverDataset(val_df, image_size=image_size)\n    \n    return train_dataset_full, val_dataset_full, train_df, val_df\n\n# –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç\nprint(\"üîÑ Creating FULL datasets...\")\ntrain_dataset_full, val_dataset_full, train_df_full, val_df_full = create_full_datasets(df_ready)\n\nprint(\"‚úÖ Full datasets created!\")\nprint(f\"üéØ You now have {len(train_dataset_full)} training samples\")\nprint(f\"üéØ and {len(val_dataset_full)} validation samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T18:16:40.004373Z","iopub.execute_input":"2025-11-29T18:16:40.004960Z","iopub.status.idle":"2025-11-29T18:16:40.022235Z","shell.execute_reply.started":"2025-11-29T18:16:40.004932Z","shell.execute_reply":"2025-11-29T18:16:40.021294Z"}},"outputs":[{"name":"stdout","text":"üîÑ Creating FULL datasets...\nüìä Original dataset size: 58638 samples\nüìä Training samples: 46910\nüìä Validation samples: 11728\nüìä Total samples: 58638\n‚úÖ Full datasets created!\nüéØ You now have 46910 training samples\nüéØ and 11728 validation samples\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Cell 7.2: Full Dataset Training\ndef setup_full_training(train_dataset, val_dataset):\n    \"\"\"–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ\"\"\"\n    \n    # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n    BATCH_SIZE = 8  # –£–º–µ–Ω—å—à–∞–µ–º batch size –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n    NUM_WORKERS = 4\n    \n    print(f\"‚ö° FULL DATASET Training setup:\")\n    print(f\"  Batch size: {BATCH_SIZE}\")\n    print(f\"  Workers: {NUM_WORKERS}\")\n    print(f\"  Training samples: {len(train_dataset)}\")\n    print(f\"  Validation samples: {len(val_dataset)}\")\n    \n    # DataLoader'—ã –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n    train_loader_full = DataLoader(\n        train_dataset, \n        batch_size=BATCH_SIZE, \n        shuffle=True, \n        num_workers=NUM_WORKERS,\n        pin_memory=True\n    )\n    \n    val_loader_full = DataLoader(\n        val_dataset, \n        batch_size=BATCH_SIZE, \n        shuffle=False, \n        num_workers=NUM_WORKERS,\n        pin_memory=True\n    )\n    \n    model_full = UNet(n_channels=1, n_classes=3)\n    \n    print(f\"üìä Batches per epoch: {len(train_loader_full)}\")\n    \n    # –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n    estimated_time = len(train_loader_full) * 0.1  # ~0.1 —Å–µ–∫ –Ω–∞ –±–∞—Ç—á —Å GPU\n    print(f\"‚è±Ô∏è Estimated time per epoch: {estimated_time/60:.1f} minutes\")\n    \n    return model_full, train_loader_full, val_loader_full\n\n# –§—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ\ndef train_full_dataset(model, train_loader, val_loader, num_epochs=10, device='cuda'):\n    \"\"\"–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ\"\"\"\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n    \n    model.to(device)\n    train_losses, val_losses = [], []\n    \n    print(f\"üöÄ Starting FULL DATASET training on {len(train_loader.dataset)} samples...\")\n    \n    for epoch in range(num_epochs):\n        # Training\n        model.train()\n        running_loss = 0.0\n        start_time = time.time()\n        \n        print(f'\\nüéØ Epoch {epoch+1}/{num_epochs} - Full Dataset')\n        print('-' * 50)\n        \n        for batch_idx, (images, masks) in enumerate(train_loader):\n            images, masks = images.to(device), masks.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, masks)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            \n            # –ü—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 5%\n            if batch_idx % max(1, len(train_loader) // 20) == 0:\n                progress = (batch_idx + 1) / len(train_loader) * 100\n                avg_loss = running_loss / (batch_idx + 1)\n                print(f'  Progress: {progress:.0f}% | Loss: {avg_loss:.4f}')\n        \n        # Validation\n        model.eval()\n        val_loss = 0.0\n        \n        with torch.no_grad():\n            for images, masks in val_loader:\n                images, masks = images.to(device), masks.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, masks)\n                val_loss += loss.item()\n        \n        # Calculate metrics\n        epoch_train_loss = running_loss / len(train_loader)\n        epoch_val_loss = val_loss / len(val_loader)\n        epoch_time = time.time() - start_time\n        \n        train_losses.append(epoch_train_loss)\n        val_losses.append(epoch_val_loss)\n        \n        print(f'‚úÖ Epoch {epoch+1} Complete:')\n        print(f'   ‚è±Ô∏è  Time: {epoch_time/60:.1f} min')\n        print(f'   üìâ Train Loss: {epoch_train_loss:.4f}')\n        print(f'   üìä Val Loss: {epoch_val_loss:.4f}')\n        \n        # Save best model\n        if epoch_val_loss == min(val_losses):\n            torch.save(model.state_dict(), 'best_unet_liver_full.pth')\n            print(f'   üíæ Best model saved!')\n    \n    return train_losses, val_losses\n\n# –ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø –ù–ê –ü–û–õ–ù–û–ú –î–ê–¢–ê–°–ï–¢–ï\nprint(\"‚ö° Setting up FULL dataset training...\")\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel_full, train_loader_full, val_loader_full = setup_full_training(train_dataset_full, val_dataset_full)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T18:16:46.868636Z","iopub.execute_input":"2025-11-29T18:16:46.868902Z","iopub.status.idle":"2025-11-29T18:16:47.312283Z","shell.execute_reply.started":"2025-11-29T18:16:46.868885Z","shell.execute_reply":"2025-11-29T18:16:47.311570Z"}},"outputs":[{"name":"stdout","text":"‚ö° Setting up FULL dataset training...\n‚ö° FULL DATASET Training setup:\n  Batch size: 8\n  Workers: 4\n  Training samples: 46910\n  Validation samples: 11728\nüìä Batches per epoch: 5864\n‚è±Ô∏è Estimated time per epoch: 9.8 minutes\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"\n\n# –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ\ntrain_losses, val_losses = train_full_dataset(\n    model_full, train_loader_full, val_loader_full, \n    num_epochs=5,  # –ú–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–æ 10-20\n    device=device\n)\n\ntorch.save(model_full.state_dict(), 'final_unet_liver_full.pth')\nprint(\"üéâ FULL DATASET training completed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T10:32:58.364121Z","iopub.execute_input":"2025-11-29T10:32:58.364963Z","iopub.status.idle":"2025-11-29T16:32:12.408411Z","shell.execute_reply.started":"2025-11-29T10:32:58.364932Z","shell.execute_reply":"2025-11-29T16:32:12.407454Z"}},"outputs":[{"name":"stdout","text":"‚ö° Setting up FULL dataset training...\n‚ö° FULL DATASET Training setup:\n  Batch size: 8\n  Workers: 4\n  Training samples: 46910\n  Validation samples: 11728\nüìä Batches per epoch: 5864\n‚è±Ô∏è Estimated time per epoch: 9.8 minutes\nüöÄ Starting FULL DATASET training on 46910 samples...\n\nüéØ Epoch 1/5 - Full Dataset\n--------------------------------------------------\n  Progress: 0% | Loss: 1.0412\n  Progress: 5% | Loss: 0.3912\n  Progress: 10% | Loss: 0.2804\n  Progress: 15% | Loss: 0.2175\n  Progress: 20% | Loss: 0.1782\n  Progress: 25% | Loss: 0.1518\n  Progress: 30% | Loss: 0.1322\n  Progress: 35% | Loss: 0.1178\n  Progress: 40% | Loss: 0.1063\n  Progress: 45% | Loss: 0.0972\n  Progress: 50% | Loss: 0.0895\n  Progress: 55% | Loss: 0.0832\n  Progress: 60% | Loss: 0.0779\n  Progress: 65% | Loss: 0.0734\n  Progress: 70% | Loss: 0.0693\n  Progress: 75% | Loss: 0.0656\n  Progress: 80% | Loss: 0.0624\n  Progress: 85% | Loss: 0.0595\n  Progress: 90% | Loss: 0.0571\n  Progress: 95% | Loss: 0.0548\n  Progress: 100% | Loss: 0.0526\n‚úÖ Epoch 1 Complete:\n   ‚è±Ô∏è  Time: 71.7 min\n   üìâ Train Loss: 0.0526\n   üìä Val Loss: 0.0199\n   üíæ Best model saved!\n\nüéØ Epoch 2/5 - Full Dataset\n--------------------------------------------------\n  Progress: 0% | Loss: 0.0174\n  Progress: 5% | Loss: 0.0106\n  Progress: 10% | Loss: 0.0107\n  Progress: 15% | Loss: 0.0111\n  Progress: 20% | Loss: 0.0109\n  Progress: 25% | Loss: 0.0106\n  Progress: 30% | Loss: 0.0107\n  Progress: 35% | Loss: 0.0103\n  Progress: 40% | Loss: 0.0101\n  Progress: 45% | Loss: 0.0098\n  Progress: 50% | Loss: 0.0097\n  Progress: 55% | Loss: 0.0096\n  Progress: 60% | Loss: 0.0093\n  Progress: 65% | Loss: 0.0093\n  Progress: 70% | Loss: 0.0092\n  Progress: 75% | Loss: 0.0093\n  Progress: 80% | Loss: 0.0092\n  Progress: 85% | Loss: 0.0092\n  Progress: 90% | Loss: 0.0090\n  Progress: 95% | Loss: 0.0090\n  Progress: 100% | Loss: 0.0088\n‚úÖ Epoch 2 Complete:\n   ‚è±Ô∏è  Time: 71.7 min\n   üìâ Train Loss: 0.0088\n   üìä Val Loss: 0.0067\n   üíæ Best model saved!\n\nüéØ Epoch 3/5 - Full Dataset\n--------------------------------------------------\n  Progress: 0% | Loss: 0.0145\n  Progress: 5% | Loss: 0.0056\n  Progress: 10% | Loss: 0.0060\n  Progress: 15% | Loss: 0.0059\n  Progress: 20% | Loss: 0.0057\n  Progress: 25% | Loss: 0.0059\n  Progress: 30% | Loss: 0.0061\n  Progress: 35% | Loss: 0.0062\n  Progress: 40% | Loss: 0.0061\n  Progress: 45% | Loss: 0.0061\n  Progress: 50% | Loss: 0.0060\n  Progress: 55% | Loss: 0.0059\n  Progress: 60% | Loss: 0.0059\n  Progress: 65% | Loss: 0.0059\n  Progress: 70% | Loss: 0.0059\n  Progress: 75% | Loss: 0.0059\n  Progress: 80% | Loss: 0.0059\n  Progress: 85% | Loss: 0.0059\n  Progress: 90% | Loss: 0.0059\n  Progress: 95% | Loss: 0.0058\n  Progress: 100% | Loss: 0.0057\n‚úÖ Epoch 3 Complete:\n   ‚è±Ô∏è  Time: 71.9 min\n   üìâ Train Loss: 0.0057\n   üìä Val Loss: 0.0044\n   üíæ Best model saved!\n\nüéØ Epoch 4/5 - Full Dataset\n--------------------------------------------------\n  Progress: 0% | Loss: 0.0024\n  Progress: 5% | Loss: 0.0046\n  Progress: 10% | Loss: 0.0046\n  Progress: 15% | Loss: 0.0048\n  Progress: 20% | Loss: 0.0049\n  Progress: 25% | Loss: 0.0056\n  Progress: 30% | Loss: 0.0055\n  Progress: 35% | Loss: 0.0054\n  Progress: 40% | Loss: 0.0053\n  Progress: 45% | Loss: 0.0051\n  Progress: 50% | Loss: 0.0050\n  Progress: 55% | Loss: 0.0050\n  Progress: 60% | Loss: 0.0050\n  Progress: 65% | Loss: 0.0049\n  Progress: 70% | Loss: 0.0049\n  Progress: 75% | Loss: 0.0048\n  Progress: 80% | Loss: 0.0049\n  Progress: 85% | Loss: 0.0048\n  Progress: 90% | Loss: 0.0047\n  Progress: 95% | Loss: 0.0047\n  Progress: 100% | Loss: 0.0047\n‚úÖ Epoch 4 Complete:\n   ‚è±Ô∏è  Time: 72.0 min\n   üìâ Train Loss: 0.0047\n   üìä Val Loss: 0.0059\n\nüéØ Epoch 5/5 - Full Dataset\n--------------------------------------------------\n  Progress: 0% | Loss: 0.0114\n  Progress: 5% | Loss: 0.0058\n  Progress: 10% | Loss: 0.0048\n  Progress: 15% | Loss: 0.0048\n  Progress: 20% | Loss: 0.0047\n  Progress: 25% | Loss: 0.0047\n  Progress: 30% | Loss: 0.0046\n  Progress: 35% | Loss: 0.0045\n  Progress: 40% | Loss: 0.0044\n  Progress: 45% | Loss: 0.0043\n  Progress: 50% | Loss: 0.0042\n  Progress: 55% | Loss: 0.0042\n  Progress: 60% | Loss: 0.0043\n  Progress: 65% | Loss: 0.0043\n  Progress: 70% | Loss: 0.0042\n  Progress: 75% | Loss: 0.0042\n  Progress: 80% | Loss: 0.0043\n  Progress: 85% | Loss: 0.0043\n  Progress: 90% | Loss: 0.0043\n  Progress: 95% | Loss: 0.0043\n  Progress: 100% | Loss: 0.0042\n‚úÖ Epoch 5 Complete:\n   ‚è±Ô∏è  Time: 72.0 min\n   üìâ Train Loss: 0.0042\n   üìä Val Loss: 0.0038\n   üíæ Best model saved!\nüéâ FULL DATASET training completed!\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Cell 8: Model Testing and Evaluation with Memory Control\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport os\nimport pickle\nimport gc\n\ndef calculate_iou_per_class(preds, targets, n_classes=3):\n    \"\"\"Calculate IoU for each class separately\"\"\"\n    ious = []\n    \n    for cls in range(n_classes):\n        pred_cls = preds == cls\n        target_cls = targets == cls\n        \n        intersection = (pred_cls & target_cls).float().sum((1, 2))\n        union = (pred_cls | target_cls).float().sum((1, 2))\n        \n        iou = (intersection + 1e-6) / (union + 1e-6)\n        ious.append(iou.mean().item())\n    \n    return ious\n\ndef calculate_dice_per_class(preds, targets, n_classes=3):\n    \"\"\"Calculate Dice coefficient for each class\"\"\"\n    dice_scores = []\n    \n    for cls in range(n_classes):\n        pred_cls = preds == cls\n        target_cls = targets == cls\n        \n        intersection = (pred_cls & target_cls).float().sum((1, 2))\n        union = pred_cls.float().sum((1, 2)) + target_cls.float().sum((1, 2))\n        \n        dice = (2. * intersection + 1e-6) / (union + 1e-6)\n        dice_scores.append(dice.mean().item())\n    \n    return dice_scores\n\ndef test_model_incremental(model, test_loader, device='cuda', \n                          chunk_size=150, results_dir='incremental_results',\n                          resume_from=None):\n    \"\"\"\n    Test model incrementally with memory control\n    \n    Args:\n        model: Trained model\n        test_loader: DataLoader with test data\n        device: Device to run on\n        chunk_size: Number of samples to process at once\n        results_dir: Directory to save results\n        resume_from: Resume from specific chunk (None for fresh start)\n    \"\"\"\n    model.eval()\n    \n    total_samples = len(test_loader)\n    print(f\"üß™ Starting incremental testing on {total_samples} samples...\")\n    print(f\"üì¶ Chunk size: {chunk_size}\")\n    print(f\"üíæ Results directory: {results_dir}\")\n    \n    # Create results directory\n    os.makedirs(results_dir, exist_ok=True)\n    \n    # Initialize or load existing results\n    if resume_from is not None and os.path.exists(f'{results_dir}/current_progress.pkl'):\n        with open(f'{results_dir}/current_progress.pkl', 'rb') as f:\n            progress = pickle.load(f)\n        print(f\"üîÑ Resuming from chunk {progress['current_chunk']}, sample {progress['processed_samples']}\")\n    else:\n        progress = {\n            'current_chunk': 0,\n            'processed_samples': 0,\n            'all_preds': [],\n            'all_targets': [],\n            'chunk_metrics': [],\n            'total_iou': 0.0,\n            'total_dice': 0.0,\n            'total_class_ious': [0.0, 0.0, 0.0],\n            'total_class_dice': [0.0, 0.0, 0.0]\n        }\n        # Clean previous results\n        for f in os.listdir(results_dir):\n            if f.startswith('chunk_') and f.endswith('.pkl'):\n                os.remove(f'{results_dir}/{f}')\n    \n    start_chunk = progress['current_chunk']\n    start_sample = progress['processed_samples']\n    \n    # Process in chunks\n    for chunk_idx in range(start_chunk, (total_samples + chunk_size - 1) // chunk_size):\n        start_idx = chunk_idx * chunk_size\n        end_idx = min((chunk_idx + 1) * chunk_size, total_samples)\n        \n        print(f\"\\n{'='*50}\")\n        print(f\"üîÑ Processing chunk {chunk_idx + 1}/{(total_samples + chunk_size - 1)//chunk_size}\")\n        print(f\"üìä Samples {start_idx} to {end_idx - 1}\")\n        \n        # Process current chunk\n        chunk_results = process_chunk(\n            model, test_loader, device, start_idx, end_idx, chunk_idx\n        )\n        \n        # Update progress\n        progress = update_progress(progress, chunk_results, results_dir)\n        \n        # Save chunk results\n        save_chunk_results(chunk_results, chunk_idx, results_dir)\n        \n        # Clear memory\n        clear_memory()\n        \n        # Print intermediate results\n        print_intermediate_results(progress, chunk_idx + 1)\n        \n        # Save checkpoint after each chunk\n        save_checkpoint(progress, results_dir)\n    \n    # Final results\n    final_results = compile_final_results(progress, results_dir)\n    \n    return final_results\n\ndef process_chunk(model, test_loader, device, start_idx, end_idx, chunk_idx):\n    \"\"\"Process a single chunk of data\"\"\"\n    chunk_iou = 0.0\n    chunk_dice = 0.0\n    chunk_class_ious = [0.0, 0.0, 0.0]\n    chunk_class_dice = [0.0, 0.0, 0.0]\n    \n    chunk_preds = []\n    chunk_targets = []\n    chunk_samples = 0\n    \n    print(f\"  Processing samples {start_idx} to {end_idx-1}...\")\n    \n    with torch.no_grad():\n        for i, (images, masks) in enumerate(test_loader):\n            if i < start_idx:\n                continue\n            if i >= end_idx:\n                break\n                \n            # Move data to GPU\n            images = images.to(device, non_blocking=True)\n            masks = masks.to(device, non_blocking=True)\n            \n            # Forward pass\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1)\n            \n            # Calculate metrics\n            ious = calculate_iou_per_class(preds, masks)\n            dice_scores = calculate_dice_per_class(preds, masks)\n            \n            chunk_iou += np.mean(ious)\n            chunk_dice += np.mean(dice_scores)\n            \n            for cls in range(3):\n                chunk_class_ious[cls] += ious[cls]\n                chunk_class_dice[cls] += dice_scores[cls]\n            \n            # Store predictions and targets (use CPU to save GPU memory)\n            chunk_preds.extend(preds.cpu().numpy().flatten())\n            chunk_targets.extend(masks.cpu().numpy().flatten())\n            \n            chunk_samples += 1\n            \n            # Progress reporting\n            if (i - start_idx) % 50 == 0:\n                current_sample = start_idx + (i - start_idx)\n                print(f\"    Sample {current_sample}/{end_idx-1} - \"\n                      f\"Current chunk IoU: {chunk_iou/chunk_samples:.4f}\")\n                \n                if torch.cuda.is_available():\n                    memory_allocated = torch.cuda.memory_allocated() / 1024**3\n                    memory_reserved = torch.cuda.memory_reserved() / 1024**3\n                    print(f\"    GPU memory: {memory_allocated:.2f} GB / {memory_reserved:.2f} GB\")\n    \n    # Calculate chunk averages\n    if chunk_samples > 0:\n        chunk_iou /= chunk_samples\n        chunk_dice /= chunk_samples\n        chunk_class_ious = [iou / chunk_samples for iou in chunk_class_ious]\n        chunk_class_dice = [dice / chunk_samples for dice in chunk_class_dice]\n    \n    return {\n        'chunk_idx': chunk_idx,\n        'start_idx': start_idx,\n        'end_idx': end_idx,\n        'samples_processed': chunk_samples,\n        'chunk_iou': chunk_iou,\n        'chunk_dice': chunk_dice,\n        'chunk_class_ious': chunk_class_ious,\n        'chunk_class_dice': chunk_class_dice,\n        'chunk_preds': chunk_preds,\n        'chunk_targets': chunk_targets\n    }\n\ndef update_progress(progress, chunk_results, results_dir):\n    \"\"\"Update overall progress with chunk results\"\"\"\n    chunk_samples = chunk_results['samples_processed']\n    \n    if chunk_samples > 0:\n        progress['current_chunk'] = chunk_results['chunk_idx'] + 1\n        progress['processed_samples'] = chunk_results['end_idx']\n        \n        # Update cumulative metrics\n        progress['total_iou'] += chunk_results['chunk_iou'] * chunk_samples\n        progress['total_dice'] += chunk_results['chunk_dice'] * chunk_samples\n        \n        for cls in range(3):\n            progress['total_class_ious'][cls] += chunk_results['chunk_class_ious'][cls] * chunk_samples\n            progress['total_class_dice'][cls] += chunk_results['chunk_class_dice'][cls] * chunk_samples\n        \n        # Store predictions and targets\n        progress['all_preds'].extend(chunk_results['chunk_preds'])\n        progress['all_targets'].extend(chunk_results['chunk_targets'])\n        progress['chunk_metrics'].append({\n            'chunk': chunk_results['chunk_idx'],\n            'iou': chunk_results['chunk_iou'],\n            'dice': chunk_results['chunk_dice']\n        })\n    \n    return progress\n\ndef save_chunk_results(chunk_results, chunk_idx, results_dir):\n    \"\"\"Save individual chunk results\"\"\"\n    chunk_filename = f'{results_dir}/chunk_{chunk_idx:04d}.pkl'\n    with open(chunk_filename, 'wb') as f:\n        pickle.dump(chunk_results, f)\n    print(f\"üíæ Chunk {chunk_idx} results saved: {chunk_filename}\")\n\ndef clear_memory():\n    \"\"\"Clear GPU and CPU memory\"\"\"\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    gc.collect()\n\ndef print_intermediate_results(progress, current_chunk):\n    \"\"\"Print intermediate results after each chunk\"\"\"\n    total_processed = progress['processed_samples']\n    if total_processed > 0:\n        current_iou = progress['total_iou'] / total_processed\n        current_dice = progress['total_dice'] / total_processed\n        \n        print(f\"üìä After {current_chunk} chunks ({total_processed} samples):\")\n        print(f\"   Current Mean IoU: {current_iou:.4f}\")\n        print(f\"   Current Mean Dice: {current_dice:.4f}\")\n\ndef save_checkpoint(progress, results_dir):\n    \"\"\"Save progress checkpoint\"\"\"\n    checkpoint_file = f'{results_dir}/current_progress.pkl'\n    with open(checkpoint_file, 'wb') as f:\n        pickle.dump(progress, f)\n    print(f\"üíæ Progress checkpoint saved\")\n\ndef compile_final_results(progress, results_dir):\n    \"\"\"Compile final results from all chunks\"\"\"\n    total_samples = progress['processed_samples']\n    \n    if total_samples > 0:\n        mean_iou = progress['total_iou'] / total_samples\n        mean_dice = progress['total_dice'] / total_samples\n        class_ious = [iou / total_samples for iou in progress['total_class_ious']]\n        class_dice = [dice / total_samples for dice in progress['total_class_dice']]\n    else:\n        mean_iou, mean_dice, class_ious, class_dice = 0.0, 0.0, [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]\n    \n    final_results = {\n        'total_samples': total_samples,\n        'mean_iou': mean_iou,\n        'mean_dice': mean_dice,\n        'class_ious': class_ious,\n        'class_dice': class_dice,\n        'all_preds': progress['all_preds'],\n        'all_targets': progress['all_targets'],\n        'chunk_metrics': progress['chunk_metrics']\n    }\n    \n    # Save final results\n    with open(f'{results_dir}/final_results.pkl', 'wb') as f:\n        pickle.dump(final_results, f)\n    \n    # Clean up checkpoint\n    checkpoint_file = f'{results_dir}/current_progress.pkl'\n    if os.path.exists(checkpoint_file):\n        os.remove(checkpoint_file)\n    \n    print(f\"‚úÖ Final results compiled for {total_samples} samples\")\n    return final_results\n\ndef plot_progress(progress, results_dir):\n    \"\"\"Plot metrics progress across chunks\"\"\"\n    chunks = [m['chunk'] for m in progress['chunk_metrics']]\n    ious = [m['iou'] for m in progress['chunk_metrics']]\n    dices = [m['dice'] for m in progress['chunk_metrics']]\n    \n    plt.figure(figsize=(12, 4))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(chunks, ious, 'b-', label='IoU', marker='o')\n    plt.axhline(y=progress['total_iou']/progress['processed_samples'], \n                color='r', linestyle='--', label='Overall IoU')\n    plt.xlabel('Chunk')\n    plt.ylabel('IoU')\n    plt.title('IoU Progress by Chunk')\n    plt.legend()\n    plt.grid(True)\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(chunks, dices, 'g-', label='Dice', marker='s')\n    plt.axhline(y=progress['total_dice']/progress['processed_samples'], \n                color='r', linestyle='--', label='Overall Dice')\n    plt.xlabel('Chunk')\n    plt.ylabel('Dice')\n    plt.title('Dice Progress by Chunk')\n    plt.legend()\n    plt.grid(True)\n    \n    plt.tight_layout()\n    plt.savefig(f'{results_dir}/progress_plot.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n# –ó–ê–ü–£–°–ö –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø\nprint(\"üß™ Loading trained model for incremental testing...\")\n\n# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\nif torch.cuda.is_available():\n    device = torch.device('cuda')\n    print(f\"‚úÖ GPU is available: {torch.cuda.get_device_name()}\")\n    print(f\"üíæ GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\nelse:\n    device = torch.device('cpu')\n    print(\"‚ö†Ô∏è  GPU not available, using CPU\")\n\nmodel_test = UNet(n_channels=1, n_classes=3)\n\ntry:\n    checkpoint = torch.load('/kaggle/input/model/other/default/1/best_unet_liver_full.pth', map_location=device)\n    model_test.load_state_dict(checkpoint)\n    print(\"‚úÖ Best model loaded successfully!\")\nexcept Exception as e:\n    try:\n        checkpoint = torch.load('final_unet_liver_full.pth', map_location=device)\n        model_test.load_state_dict(checkpoint)\n        print(\"‚úÖ Final model loaded successfully!\")\n    except Exception as e:\n        print(f\"‚ùå No trained model found: {e}\")\n        model_test = None\n\nif model_test is not None:\n    model_test = model_test.to(device)\n    model_test.eval()\n    \n    # –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ\n    print(\"\\nüî¨ Starting incremental evaluation with memory control...\")\n    final_results = test_model_incremental(\n        model_test, \n        val_loader_full, \n        device=device, \n        chunk_size=150,  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ 150 —Ñ–∞–π–ª–æ–≤ –∑–∞ —Ä–∞–∑\n        results_dir='incremental_evaluation',\n        resume_from=None  # –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å —á–∞–Ω–∫ –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è\n    )\n    \n    if final_results is not None:\n        # –í—ã–≤–æ–¥–∏–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n        print(\"\\n\" + \"=\"*60)\n        print(\"üéØ FINAL MODEL EVALUATION RESULTS\")\n        print(\"=\"*60)\n        print(f\"üìä Total tested samples: {final_results['total_samples']}\")\n        print(f\"üéØ Mean IoU: {final_results['mean_iou']:.4f}\")\n        print(f\"üéØ Mean Dice: {final_results['mean_dice']:.4f}\")\n        print(\"\\nüìà Per-class metrics:\")\n        class_names = ['Background', 'Liver', 'Tumor']\n        for cls, (iou, dice) in enumerate(zip(final_results['class_ious'], final_results['class_dice'])):\n            print(f\"  {class_names[cls]:12} | IoU: {iou:.4f} | Dice: {dice:.4f}\")\n        \n        # Benchmark quality\n        avg_iou = final_results['mean_iou']\n        if avg_iou > 0.7:\n            print(\"üéâ EXCELLENT model quality!\")\n        elif avg_iou > 0.5:\n            print(\"‚úÖ GOOD model quality!\")\n        elif avg_iou > 0.3:\n            print(\"‚ö†Ô∏è  FAIR model quality - consider more training\")\n        else:\n            print(\"‚ùå POOR model quality - needs improvement\")\n    \n    # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å\n    clear_memory()\n    print(\"üßπ Memory cleared\")\nelse:\n    print(\"Please train the model first using Cell 7!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T18:17:05.723824Z","iopub.execute_input":"2025-11-29T18:17:05.724536Z","execution_failed":"2025-11-29T18:22:24.358Z"}},"outputs":[{"name":"stdout","text":"üß™ Loading trained model for incremental testing...\n‚úÖ GPU is available: Tesla T4\nüíæ GPU memory: 14.7 GB\n‚úÖ Best model loaded successfully!\n\nüî¨ Starting incremental evaluation with memory control...\nüß™ Starting incremental testing on 1466 samples...\nüì¶ Chunk size: 150\nüíæ Results directory: incremental_evaluation\n\n==================================================\nüîÑ Processing chunk 1/10\nüìä Samples 0 to 149\n  Processing samples 0 to 149...\n    Sample 0/149 - Current chunk IoU: 0.9460\n    GPU memory: 0.28 GB / 2.17 GB\n    Sample 50/149 - Current chunk IoU: 0.9607\n    GPU memory: 0.28 GB / 2.17 GB\n    Sample 100/149 - Current chunk IoU: 0.9577\n    GPU memory: 0.28 GB / 2.17 GB\n","output_type":"stream"}],"execution_count":null}]}